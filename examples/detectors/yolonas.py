# Mikel Brostr√∂m üî• Yolo Tracking üßæ AGPL-3.0 license

import numpy as np
import torch
from super_gradients.common.object_names import Models
from super_gradients.training import models
from ultralytics.engine.results import Results
from ultralytics.utils import ops

from boxmot.utils import logger as LOGGER
from examples.detectors.yolo_interface import YoloInterface


class YoloNASStrategy(YoloInterface):
    pt = False
    stride = 32
    fp16 = False
    triton = False
    names = {
        0: 'ng∆∞·ªùi', 1: 'xe ƒë·∫°p', 2: '√¥ t√¥', 3: 'xe m√°y', 4: 'm√°y bay', 5: 'xe bu√Ωt',
        6: 't√†u h·ªèa', 7: 'xe t·∫£i', 8: 'thuy·ªÅn', 9: 'ƒë√®n t√≠n hi·ªáu giao th√¥ng', 10: 'v√≤i ch·ªØa ch√°y',
        11: 'bi·ªÉn b√°o d·ª´ng xe', 12: 'ƒë·ªìng h·ªì t√≠nh ti·ªÅn ƒë·ªó xe', 13: 'gh·∫ø d√†i', 14: 'con chim', 15: 'con m√®o',
        16: 'con ch√≥', 17: 'con ng·ª±a', 18: 'con c·ª´u', 19: 'con b√≤', 20: 'con voi',
        21: 'con g·∫•u', 22: 'con ng·ª±a v·∫±n', 23: 'con h∆∞∆°u cao c·ªï', 24: 'balo', 25: 'c√¢y d√π',
        26: 't√∫i x√°ch', 27: 'c√† v·∫°t', 28: 'vali', 29: 'ƒëƒ©a frisbee', 30: 'v√°n tr∆∞·ª£t tuy·∫øt',
        31: 'v√°n tr∆∞·ª£t tuy·∫øt v√°n ƒë√¥i', 32: 'qu·∫£ b√≥ng th·ªÉ thao', 33: 'con di·ªÅu', 34: 'g·∫≠y b√≥ng ch√†y', 35: 'gƒÉng tay b√≥ng ch√†y',
        36: 'v√°n tr∆∞·ª£t', 37: 'v√°n l∆∞·ªõt s√≥ng', 38: 'v·ª£t tennis', 39: 'chai', 40: 'ly r∆∞·ª£u vang',
        41: 't√°ch', 42: 'nƒ©a', 43: 'dao', 44: 'mu·ªóng', 45: 't√¥',
        46: 'chu·ªëi', 47: 't√°o', 48: 'sandwich', 49: 'cam', 50: 'b√¥ng c·∫£i xanh',
        51: 'c√† r·ªët', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'b√°nh ng·ªçt',
        56: 'gh·∫ø', 57: 'gh·∫ø sofa', 58: 'c√¢y c·∫£nh trong ch·∫≠u', 59: 'gi∆∞·ªùng', 60: 'b√†n ƒÉn',
        61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'chu·ªôt m√°y t√≠nh', 65: 'ƒëi·ªÅu khi·ªÉn',
        66: 'b√†n ph√≠m', 67: 'ƒëi·ªán tho·∫°i di ƒë·ªông', 68: 'l√≤ vi s√≥ng', 69: 'l√≤ n∆∞·ªõng', 70: 'm√°y n∆∞·ªõng b√°nh m√¨',
        71: 'b·ªìn r·ª≠a b√°t', 72: 't·ªß l·∫°nh', 73: 's√°ch', 74: 'ƒë·ªìng h·ªì', 75: 'l·ªç hoa',
        76: 'k√©o', 77: 'g·∫•u b√¥ng', 78: 'm√°y s·∫•y t√≥c', 79: 'b√†n ch·∫£i ƒë√°nh rƒÉng'
    }

    def __init__(self, model, device, args):
        self.args = args

        avail_models = [x.lower() for x in list(Models.__dict__.keys())]
        model_type = self.get_model_from_weigths(avail_models, model)

        LOGGER.info(f'Loading {model_type} with {str(model)}')
        if not model.exists() and model.stem == model_type:
            LOGGER.info('Downloading pretrained weights...')
            self.model = models.get(
                model_type,
                pretrained_weights="coco"
            ).to(device)
        else:
            self.model = models.get(
                model_type,
                num_classes=-1,  # set your num classes
                checkpoint_path=str(model)
            ).to(device)

        self.device = device

    @torch.no_grad()
    def __call__(self, im, augment, visualize):

        im = im[0].permute(1, 2, 0).cpu().numpy() * 255

        with torch.no_grad():
            preds = self.model.predict(
                im,
                iou=0.5,
                conf=0.7,
                fuse_model=False
            )[0].prediction

        preds = np.concatenate(
            [
                preds.bboxes_xyxy,
                preds.confidence[:, np.newaxis],
                preds.labels[:, np.newaxis]
            ], axis=1
        )

        preds = torch.from_numpy(preds).unsqueeze(0)

        return preds

    def warmup(self, imgsz):
        pass

    def postprocess(self, path, preds, im, im0s):

        results = []
        for i, pred in enumerate(preds):

            if pred is None:
                pred = torch.empty((0, 6))
                r = Results(
                    path=path,
                    boxes=pred,
                    orig_img=im0s[i],
                    names=self.names
                )
                results.append(r)
            else:

                pred[:, :4] = ops.scale_boxes(im.shape[2:], pred[:, :4], im0s[i].shape)

                # filter boxes by classes
                if self.args.classes:
                    pred = pred[torch.isin(pred[:, 5].cpu(), torch.as_tensor(self.args.classes))]

                r = Results(
                    path=path,
                    boxes=pred,
                    orig_img=im0s[i],
                    names=self.names
                )
            results.append(r)
        return results
